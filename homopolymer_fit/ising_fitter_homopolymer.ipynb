{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ising fitter for capped homopolymer repeat proteins.\n",
    "\n",
    "Authors:  Doug Barrick, Jacob D. Marold, Kathryn Geiger-Schuller, Tural Aksel, Ekaterina Poliakova-Georgantas, Sean Klein, Kevin Sforza, Mark Peterson\n",
    "\n",
    "This notebook performs an Ising model fit to consensus Ankyrin repeat proteins (cANK). It reads data from Aviv data files, converts the data to normalized unfolding transitions, generates partition functions and expressions for fraction folded, and uses these expressions to fit the normalized transitions.  Data and fits are plotted in various ways, and bootstrap analysis is performed.  Correlation plots are generated for pairs of bootstrap parameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, path, and project name\n",
    "\n",
    "Path and project name should be set by the user.  Note that because of the kernel restart below, these must be specified in subsequent scripts, along with any other imports that are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np  \n",
    "import glob     \n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import sympy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import lmfit\n",
    "import math\n",
    "\n",
    "path = os.getcwd() # change this to package path once we make setup.py\n",
    "proj_name = 'cANK'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data conversion.\n",
    "\n",
    "Data are read from an Aviv.dat file.\n",
    "\n",
    "Outputs are\n",
    "\n",
    "1.  A numpy data file for each melt, contining [denaturant], normalized signal, construct ID, and melt ID.\n",
    "\n",
    "2.  A list of constructs.\n",
    "\n",
    "3.  A list of melts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cd_signal_from_aviv(filepath):\n",
    "    \"\"\"Extracts the X,Y values (denaturant, CD signal) from an Aviv .dat file \n",
    "    Accepts:\n",
    "        -filepath: str the filepath location of the .dat file\n",
    "    Returns:\n",
    "        - np.array(float[])\n",
    "    \"\"\"\n",
    "    xylist = []\n",
    "    with open(filename, 'r') as f: \n",
    "        \n",
    "        lines = f.read().splitlines() #define the beginning and end of the data\n",
    "        begin = 0\n",
    "        end = 0\n",
    "        \n",
    "        while not lines[begin] == '$DATA':\n",
    "            begin = begin + 1\n",
    "        begin = begin + 4\n",
    "        \n",
    "        while not lines[end] == '$ENDDATA':\n",
    "            end = end + 1    \n",
    "            \n",
    "        for row in range(begin, end - 1):  #extract the [denat] and CD signal\n",
    "            line = lines[row]\n",
    "            n = line.split()\n",
    "            xylist.append([float(n[0]), float(n[1])])\n",
    "    \n",
    "    return np.array(xylist)\n",
    "\n",
    "def normalize_y_values(xy):\n",
    "    \"\"\"Normalizes the y values of the signal\n",
    "    \n",
    "    Accepts: np.array(float[])\n",
    "    Returns: float[]\n",
    "    \"\"\"\n",
    "    maxval = max(xy[:,1])\n",
    "    minval = min(xy[:,1])\n",
    "    normylist = [float(((xy[i,1] - maxval)/(minval - maxval))) for i in range(len(xy))]\n",
    "    return normylist\n",
    "\n",
    "\n",
    "def organize_constructs_by_name(melts):\n",
    "    ''' \n",
    "    This loop puts melts in order of type (NRxC, NRx, RxC) and length.  This is useful for the\n",
    "    plotting script below, putting the by_melt legends in a sensible order\n",
    "    \n",
    "    Accepts: str[] - construct names\n",
    "    Returns: str[] - ordered construct names\n",
    "    '''\n",
    "    NRClist = []\n",
    "    NRlist = []\n",
    "    RClist = []\n",
    "    melts.sort()  # Puts in order based on length\n",
    "    for melt in melts:\n",
    "        if melt[0] == 'N':\n",
    "            if melt[-3] == 'C':\n",
    "                NRClist.append(melt)\n",
    "            else:\n",
    "                NRlist.append(melt)\n",
    "        else:\n",
    "            RClist.append(melt)\n",
    "            \n",
    "    melts = NRClist + NRlist + RClist\n",
    "    return melts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "den_nsig_const_melt = []\n",
    "constructs = [] # List of constructs used to build partition functions and\n",
    "melts = []  # List of melts to be used in fitting.\n",
    "den_nsig_const_melt_df = []\n",
    "\n",
    "# Gets file names, and extracts information including construct name, melt number.      \n",
    "for num, filename in enumerate(glob.glob(os.path.join(path, \"NRC_data\", \"*.dat\"))):\n",
    "    num = num + 1\n",
    "    base = os.path.basename(filename)\n",
    "    melt = base.split(\".\")[0]\n",
    "    \n",
    "    # Store the names of each construct to map to partition functions\n",
    "    construct_name = melt[:-2]\n",
    "    if construct_name not in constructs: \n",
    "        constructs.append(construct_name)\n",
    "\n",
    "    # Reads the data portion of Aviv file\n",
    "    xyarray = extract_cd_signal_from_aviv(filename)\n",
    "\n",
    "    # Normalize the y-values from 0-1                        \n",
    "    normylist = normalize_y_values(xyarray)\n",
    "    \n",
    "    # a melt number to use as an ID for fitting in ising script.\n",
    "    single_melt_dncm = []\n",
    "    for i in range(len(xyarray)): \n",
    "        x_y_name_num = [xyarray[i,0], normylist[i], construct_name, num]\n",
    "        den_nsig_const_melt.append(x_y_name_num)\n",
    "        single_melt_dncm.append(x_y_name_num)\n",
    "\n",
    "    # Build a numpy array for each melt and output for Ising fitter.  \n",
    "    # Columns are denaturant, normalized CD, construct, melt number.\n",
    "    melt_array = np.array(single_melt_dncm)\n",
    "    np.save(os.path.join(path, melt), melt_array) # Writes an npy file to disk for each melt.\n",
    "    melt_df = pd.DataFrame(melt_array, columns=['denat','signal','construct_melt','dataset'])\n",
    "    den_nsig_const_melt_df.append(melt_df)\n",
    "    melts.append(melt)        \n",
    "\n",
    "den_nsig_const_melt_df = pd.concat(den_nsig_const_melt_df)\n",
    "den_nsig_const_melt_df.to_csv(os.path.join(path, f\"{proj_name}_combined_data.csv\"), index=False, header=False)\n",
    "\n",
    "melts = organize_constructs_by_name(melts)\n",
    "\n",
    "# Write out the results.  \n",
    "with open(os.path.join(path, f\"{proj_name}_constructs.json\"), 'w') as r:\n",
    "    json.dump(constructs, r)\n",
    "\n",
    "with open(os.path.join(path, f\"{proj_name}_melts.json\"), 'w') as s:\n",
    "    json.dump(melts, s)  \n",
    "\n",
    "stop = time.time()\n",
    "runtime = stop - start\n",
    "print('\\nThe elapsed time was ' + str(runtime) + ' sec')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "den_nsig_const_melt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a partition function and fraction folded expressions for fitting.\n",
    "\n",
    "Inputs the constructs.json, melts.json, and processed .npy data files from the data processing script above.\n",
    "\n",
    "Generates a dictionary of partition functions using the capped homopolymer 1D-Ising model, and converts these to dictionaries of fraction-folded expressions (**fraction_folded_dict**) for fitting by partial differentiation.  Manipulations are done using the sympy module which allows symbolic math operations.  This is important for partial differentiation, but also for \"simplification\" of the fraction folded exprssions.  This simplification factors common terms, significantly decreasing the time it takes to fit and bootstrap below.  The fraction-folded dictionary is exported in json format.\n",
    "\n",
    "Because the numpy exponential function (np.exp) gets reassigned in this script, and I cannot figure out how to undo this, the kernel must be restarted at the bottom of the script (exit()).  The user will be prompted to accept.\n",
    "\n",
    "Though the path, project name, and most (but not all imports) are redundant with the command above, the kernel restart at the end of this script can create problems, if the script is run more than once.  For this reason I am keeping them associated with this script (and with subsequent scripts--fitting, plotting, etc).\n",
    "\n",
    "Note that on 2020_05_05, I am changing the equation that gives the denaturant dependence of DGi to DGi + mi denat in the three equations for N, R, and C.  This corresponds to a positive m-value (free energies become more positive with denaturant).  Also change initial guess in the fitting cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_name = 'cANK'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print('Generating partition functions and fraction folded expressions.  This may take a minute...')\n",
    "\n",
    "# Parameters for partition function calculation.  Note these are sympy symbols.\n",
    "RT = sp.Symbol('RT')\n",
    "dGN = sp.Symbol('dGN')\n",
    "dGR = sp.Symbol('dGR')\n",
    "dGC = sp.Symbol('dGC')\n",
    "mi = sp.Symbol('mi')\n",
    "denat = sp.Symbol('denat')\n",
    "Kn = sp.Symbol('Kn')\n",
    "Kr = sp.Symbol('Kr')\n",
    "Kc = sp.Symbol('Kc')\n",
    "dGinter = sp.Symbol('dGinter')\n",
    "W = sp.Symbol('W')\n",
    "\n",
    "#np.exp = sp.Function('np.exp')\n",
    "exp = sp.Function('np.exp')\n",
    "\n",
    "with open(os.path.join(path, f'{proj_name}_constructs.json'), 'r') as cons:\n",
    "    constructs = json.load(cons)\n",
    "\n",
    "#define matricies  and end vectors to be used to calculate partition functions\n",
    "begin = sp.Matrix([[0,1]])\n",
    "N = sp.Matrix([[(Kn*W),1],[Kn,1]])\n",
    "R = sp.Matrix([[(Kr*W),1],[Kr,1]])\n",
    "C = sp.Matrix([[(Kc*W),1],[Kc,1]])\n",
    "end = sp.Matrix([[1],[1]])\n",
    "\n",
    "# Build dictionaries of partition functions, partial derivs with respect\n",
    "# to K, and fraction folded.\n",
    "\n",
    "q_dict = {}\n",
    "dqdKn_dict = {}\n",
    "dqdKr_dict = {}\n",
    "dqdKc_dict = {}\n",
    "frac_folded_dict = {}\n",
    "\n",
    "# Number of repeats of each type.  Seems like they should be floats, but\n",
    "# I get an error in the matrix multiplication (q_dict) if they are declared to be.\n",
    "\n",
    "for construct in constructs:\n",
    "\n",
    "    # Make partition function dictionary and expressions for fraction folded. \n",
    "    # Note, only one pf is generated per construct, even when there are multiple melts.\n",
    "    \n",
    "    matrixlist = construct.split('_')\n",
    "    q_dict[construct + '_q'] = begin \n",
    "        \n",
    "    for i in range(0,len(matrixlist)):\n",
    "        num_Ni = 0\n",
    "        num_Ri = 0\n",
    "        num_Ci = 0\n",
    "        if matrixlist[i] == 'N':\n",
    "            num_Ni=1\n",
    "        if matrixlist[i] == 'R':\n",
    "            num_Ri=1\n",
    "        if matrixlist[i] == 'C':\n",
    "            num_Ci=1\n",
    "\n",
    "        q_dict[construct + '_q'] = q_dict[construct + '_q'] *\\\n",
    "        np.linalg.matrix_power(N, num_Ni) * np.linalg.matrix_power(R, num_Ri) *\\\n",
    "        np.linalg.matrix_power(C, num_Ci) \n",
    "      \n",
    "    q_dict[construct + '_q'] =  q_dict[construct + '_q'] * end\n",
    "\n",
    "    # Next two lines convert from sp.Matrix to np.array to something else.\n",
    "    # Not sure the logic here, but it works.\n",
    "    \n",
    "    q_dict[construct + '_q'] = np.array(q_dict[construct + '_q']) \n",
    "    q_dict[construct + '_q'] = q_dict[construct + '_q'].item(0)\n",
    "\n",
    "    # Partial derivs wrt Kn dictionary.\n",
    "    dqdKn_dict[construct + '_dqdKn'] \\\n",
    "        = sp.diff(q_dict[construct + '_q'], Kn)\n",
    "\n",
    "    # Partial derivs wrt Kr dictionary.\n",
    "    dqdKr_dict[construct + '_dqdKr'] \\\n",
    "        = sp.diff(q_dict[construct + '_q'], Kr)\n",
    "\n",
    "    # Partial derivs wrt Kc dictionary.\n",
    "    dqdKc_dict[construct + '_dqdKc'] \\\n",
    "        = sp.diff(q_dict[construct + '_q'], Kc)\n",
    "\n",
    "    # Fraction folded dictionary.  \n",
    "    frac_folded_dict[construct + '_frac_folded'] \\\n",
    "        = (Kn/( q_dict[construct + '_q']) * dqdKn_dict[construct + '_dqdKn'] \\\n",
    "        + Kr/(q_dict[construct + '_q']) * dqdKr_dict[construct + '_dqdKr'] \\\n",
    "        + Kc/( q_dict[construct + '_q']) * dqdKc_dict[construct + '_dqdKc']) \\\n",
    "        / (len(matrixlist))\n",
    "\n",
    "# The loop below replaces K's and W's the fraction folded terms in the \n",
    "# dictionary with DGs, ms, and denaturant concentrations.  The simplify line\n",
    "# is really important for making compact expressions for fraction folded.\n",
    "# This simplification greatly speeds up fitting.  The last line\n",
    "# converts from a sympy object to a string, to allow for json dump.\n",
    "\n",
    "for construct in frac_folded_dict:\n",
    "    frac_folded_dict[construct] = frac_folded_dict[construct].subs({\n",
    "    Kn:(exp(-((dGN + (mi*denat))/RT))), \n",
    "    Kr:(exp(-((dGR + (mi*denat))/RT))), \n",
    "    Kc:(exp(-((dGC + (mi*denat))/RT))),  \n",
    "    W:(exp(-dGinter/RT)) }) \n",
    "    frac_folded_dict[construct] = sp.simplify(frac_folded_dict[construct])\n",
    "    frac_folded_dict[construct] = str(frac_folded_dict[construct])                                \n",
    "\n",
    "with open(os.path.join(path, f'{proj_name}_frac_folded_dict.json'), 'w') as f:\n",
    "    json.dump(frac_folded_dict, f)\n",
    "   \n",
    "stop = time.time()\n",
    "runtime = stop - start\n",
    "print('\\nThe elapsed time was ' + str(runtime) + ' sec') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the data with the Ising model\n",
    "\n",
    "Processed data files are imported along with the fraction-folded dictionary and construct and melt lists.  The fit is performed with the lmfit module, which has extra functionality over fitting routines in scipy.  \n",
    "\n",
    "Note that if your initial guesses are poor, the fit may be slowed significantly or the fit may not converge.\n",
    "\n",
    "Fitted thermodynamic parameters are outputted to the screen and are written to a csv file.  Baseline parameters are also written to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFitting the data...\\n\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "plt.close()\n",
    "plt.clf\n",
    "\n",
    "RT = 0.001987 * 298.15 #  R in kcal/mol/K, T in Kelvin.\n",
    "\n",
    "#  Dictionary of frac folded eqns from partition function generator script.\n",
    "with open(os.path.join(path, f'{proj_name}_frac_folded_dict.json'), 'r') as ffd:\n",
    "    frac_folded_dict = json.load(ffd)\n",
    "\n",
    "with open(os.path.join(path, f'{proj_name}_constructs.json'), 'r') as construct:\n",
    "    constructs = json.load(construct)\n",
    "\n",
    "with open(os.path.join(path, f'{proj_name}_melts.json'), 'r') as m:\n",
    "    melts = json.load(m)\n",
    "\n",
    "num_melts = len(melts)\n",
    "num_constructs = len(constructs)\n",
    "melt_data_dict = {melt: np.load(os.path.join(path, f'{melt}.npy')) for melt in melts}\n",
    "\n",
    "\n",
    "# Compile fraction folded expressions.\n",
    "comp_frac_folded_dict = {}\n",
    "for construct in constructs:\n",
    "    frac_folded_string = frac_folded_dict[construct + '_frac_folded']\n",
    "    comp_frac_folded = compile(frac_folded_string, '{}_comp_ff'.format(construct), 'eval')\n",
    "    comp_frac_folded_dict[construct + '_comp_ff'] = comp_frac_folded #comp_frac_folded\n",
    "\n",
    "# CREATE INITIAL GUESSES\n",
    "# First, thermodynamic parameters.  These are Global.\n",
    "init_guesses = lmfit.Parameters()\n",
    "init_guesses.add('dGN', value = 6)\n",
    "init_guesses.add('dGR', value = 5)\n",
    "init_guesses.add('dGC', value = 6)\n",
    "init_guesses.add('dGinter', value = -12)\n",
    "init_guesses.add('mi', value = 1.0)\n",
    "\n",
    "# Next, baseline parameters.  These are local.\n",
    "for melt in melts:\n",
    "    init_guesses.add('af_{}'.format(melt), value=0.02)\n",
    "    init_guesses.add('bf_{}'.format(melt), value=1)\n",
    "    init_guesses.add('au_{}'.format(melt), value=0.0)\n",
    "    init_guesses.add('bu_{}'.format(melt), value=0.0)\n",
    "\n",
    "# Transfers init_guesses to params for fitting, but init_guesses are maintained.\n",
    "params = init_guesses\n",
    "\n",
    "def fitting_function(params, denat, frac_folded, melt):\n",
    "    af = params['af_{}'.format(melt)].value\n",
    "    bf = params['bf_{}'.format(melt)].value\n",
    "    au = params['au_{}'.format(melt)].value\n",
    "    bu = params['bu_{}'.format(melt)].value\n",
    "    dGN = params['dGN'].value\n",
    "    dGR = params['dGR'].value\n",
    "    dGC = params['dGC'].value\n",
    "    dGinter = params['dGinter'].value\n",
    "    mi = params['mi'].value\n",
    "    return ((af * denat) + bf) * frac_folded + (((au * denat) + bu) * (1 - frac_folded))\n",
    "\n",
    "# Objective function creates an array of residuals to be used by lmfit minimize.\n",
    "def objective(params):\n",
    "    resid_dict = {}\n",
    "    dGN = params['dGN'].value  \n",
    "    dGR = params['dGR'].value   \n",
    "    dGC = params['dGC'].value\n",
    "    dGinter = params['dGinter'].value\n",
    "    mi = params['mi'].value\n",
    "    for melt in melts:   \n",
    "        denat = melt_data_dict[melt][:,0]     # A numpy array of type str\n",
    "        norm_sig = melt_data_dict[melt][:,1]  # A numpy array of type str\n",
    "        denat = denat.astype(float) # A numpy array of type float\n",
    "        norm_sig = norm_sig.astype(float) # A numpy array of type float\n",
    "       \n",
    "        string_to_eval = comp_frac_folded_dict[melt[:-2] + '_comp_ff']\n",
    "        frac_folded = eval(string_to_eval)\n",
    "        \n",
    "        # frac_folded name gets associated for use in fitting_function call in frac_folded_string assignment above.\n",
    "        af = params['af_{}'.format(melt)].value\n",
    "        bf = params['bf_{}'.format(melt)].value\n",
    "        au = params['au_{}'.format(melt)].value\n",
    "        bu = params['bu_{}'.format(melt)].value\n",
    "        resid = norm_sig - fitting_function(params, denat, frac_folded, melt)\n",
    "        resid_dict[melt + '_resid'] = resid\n",
    "    residuals = np.concatenate(list(resid_dict.values()))\n",
    "    return residuals\n",
    "\n",
    "# Fit with lmfit\n",
    "result = lmfit.minimize(objective, init_guesses)\n",
    "fit_resid = result.residual\n",
    "\n",
    "# Print out features of the data, the fit, and optimized param values\n",
    "print(\"There are a total of {} data sets.\".format(num_melts))\n",
    "print(\"There are {} observations.\".format(result.ndata))\n",
    "print(\"There are {} fitted parameters.\".format(result.nvarys))\n",
    "print(\"There are {} degrees of freedom. \\n\".format(result.nfree))\n",
    "print(\"The sum of squared residuals (SSR) is: {0:7.4f}\".format(result.chisqr))\n",
    "print(\"The reduced SSR (SSR/DOF): {0:8.6f} \\n\".format(result.redchi))\n",
    "\n",
    "dGN = result.params['dGN'].value\n",
    "dGR = result.params['dGR'].value\n",
    "dGC = result.params['dGC'].value\n",
    "dGinter = result.params['dGinter'].value\n",
    "mi = result.params['mi'].value\n",
    "\n",
    "print('Optimized parameter values:')\n",
    "print('dGN = {0:8.4f}'.format(result.params['dGN'].value))\n",
    "print('dGR = {0:8.4f}'.format(result.params['dGR'].value))\n",
    "print('dGC ={0:8.4f}'.format(result.params['dGC'].value))\n",
    "print('dGinter ={0:8.4f}'.format(result.params['dGinter'].value))\n",
    "print('mi ={0:8.4f}'.format(result.params['mi'].value))\n",
    "\n",
    "print(\"\\nWriting best fit parameter and baseline files\")\n",
    "\n",
    "# Compile a list of optimized Ising params and write to file.\n",
    "fitted_ising_params = [[\"dGN\", result.params['dGN'].value], \n",
    "                        [\"dGR\", result.params['dGR'].value], \n",
    "                        [\"dGC\", result.params['dGC'].value], \n",
    "                        [\"dGinter\", result.params['dGinter'].value],\n",
    "                        [\"mi\", result.params['mi'].value], \n",
    "                        [\"Chi**2\",result.chisqr],\n",
    "                        [\"RedChi\",result.redchi]]\n",
    "\n",
    "with open(os.path.join(path, f'{proj_name}_fitted_Ising_params.csv'), \"w\") as n:\n",
    "    writer = csv.writer(n, delimiter=',')\n",
    "    writer.writerows(fitted_ising_params)\n",
    "n.close()\n",
    "\n",
    "# Compile a list of optimized baseline params and write to file.\n",
    "fitted_base_params = []\n",
    "for melt in melts:\n",
    "    af = result.params['af_%s' % (melt)].value            \n",
    "    bf = result.params['bf_%s' % (melt)].value              \n",
    "    au = result.params['au_%s' % (melt)].value          \n",
    "    bu = result.params['bu_%s' % (melt)].value           \n",
    "    fitted_base_params.append([melt, af, bf, au, bu])            \n",
    "with open(os.path.join(path, f'{proj_name}_fitted_baseline_params.csv'), \"w\") as m:              \n",
    "    writer = csv.writer(m, delimiter=',')\n",
    "    writer.writerows(fitted_base_params) \n",
    "m.close()\n",
    "\n",
    "stop = time.time()\n",
    "runtime = stop - start\n",
    "print('\\nThe elapsed time was ' + str(runtime) + ' sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the results of the fit\n",
    "\n",
    "This cell generates four plots.  Two are \"normalized\" data (the data that were actually fit in the scipt above) and fits.  The other two are fraction-folded data and fits.  One each shows all the constructs, which ideally includes multiple melts of each construct, allowing all fits to be inspected.  The other shows only a single melt for each construct (the first one in the melt list for each), simplifying the plot.\n",
    "\n",
    "The resulting plots are dumped to the screen below the cell, and are saved as png files.\n",
    "\n",
    "Note that this script is meant to be run after the fitting script.  If the fit has not been performed in the current session (or the kernel was restarted after the fit--*not usually the case*), then imports will have to be run, along with data and fitted parameters.  That would be pain, so just re-run the fit again, if you find yourself in this situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPlotting results...\\n\")\n",
    "\n",
    "# The function \"baseline_adj\" gives an adjusted y value based on fitted baseline \n",
    "# parameters (fraction folded). \n",
    "def baseline_adj(y, x, params, construct):\n",
    "    af = result.params['af_{}'.format(construct)].value\n",
    "    bf = result.params['bf_{}'.format(construct)].value\n",
    "    au = result.params['au_{}'.format(construct)].value\n",
    "    bu = result.params['bu_{}'.format(construct)].value\n",
    "    return (y-(bu+(au*x)))/((bf+(af*x))-(bu+(au*x)))\n",
    "\n",
    "# Defining global best-fit parameters\n",
    "dGN = result.params['dGN'].value\n",
    "dGR = result.params['dGR'].value\n",
    "dGC = result.params['dGC'].value\n",
    "dGinter =result.params['dGinter'].value\n",
    "mi = result.params['mi'].value\n",
    "\n",
    "# The function fit_model used for plotting best-fit lines and for adding  \n",
    "# residuals to best-fit lines in bootstrapping.  Normalized, not frac folded.\n",
    "def fit_model(params, x, melt):\n",
    "    denat = x\n",
    "    af = result.params['af_{}'.format(melt)].value\n",
    "    bf = result.params['bf_{}'.format(melt)].value\n",
    "    au = result.params['au_{}'.format(melt)].value\n",
    "    bu = result.params['bu_{}'.format(melt)].value\n",
    "    frac_folded = eval(comp_frac_folded_dict[melt[:-2] + '_comp_ff']) # :-2 leaves off the _1, _2, etc from melt id.    \n",
    "    return ((af * denat) + bf) * frac_folded + (((au * denat) + bu) * \\\n",
    "            (1 - frac_folded))   \n",
    "\n",
    "# Finding the maximum denaturant value out of all the melts to\n",
    "# set x axis bound\n",
    "denat_maxer = np.zeros(0)\n",
    "for melt in melts:\n",
    "    denat_maxer = np.concatenate((denat_maxer, melt_data_dict[melt][:, 0]))\n",
    "denat_maxer_list = denat_maxer.tolist()\n",
    "denat_max = float(max(denat_maxer_list))\n",
    "denat_bound = np.around(denat_max, 1) + 0.2\n",
    "\n",
    "# Denaturant values to use when evaluating fits.  Determines how smooth the\n",
    "# fitted curve will be, based on the third value (300) in the argument below.\n",
    "# I might keep using this for fraction_foldeed, but for nomralized baseline\n",
    "# use a local set of points for each melt, so as not to extrapolate the \n",
    "# bselines too far.\n",
    "denat_fit = np.linspace(0, denat_bound, 300)\n",
    "\n",
    "#defining a dictionary using the first melt of each construct (construct_1)\n",
    "#Move this to the plotting part, and why not do this for all constructs?\n",
    "construct1_data_dict = {}\n",
    "for construct in constructs:\n",
    "    construct1_data_dict[construct] = np.load(os.path.join(path, f'{construct}_1.npy'))\n",
    "\n",
    "# The four dictionaries below define lower and upper denaturant limnits to be\n",
    "# used for plotting normalized curves, so crazy-long baseline extrapolations \n",
    "# are not shown.  Do both for melts and construct 1.   These are then used\n",
    "# to create 300-point synthetic baselines in the fifth and sixth dictionaries.\n",
    "melt_lower_denat_dict = {}\n",
    "for melt in melts:\n",
    "    melt_lower_denat_dict[melt] = round(float(min(melt_data_dict[melt][:,0]))) -0.2\n",
    "\n",
    "melt_upper_denat_dict = {}\n",
    "for melt in melts:\n",
    "    melt_upper_denat_dict[melt] = round(float(max(melt_data_dict[melt][:,0]))) + 0.2\n",
    "\n",
    "construct1_lower_denat_dict = {}\n",
    "for construct in constructs:\n",
    "    construct1_lower_denat_dict[construct] = round(float(min(construct1_data_dict[construct][:,0]))) - 0.2\n",
    "\n",
    "construct1_upper_denat_dict = {}\n",
    "for construct in constructs:\n",
    "    construct1_upper_denat_dict[construct] = round(float(max(construct1_data_dict[construct][:,0]))) + 0.2\n",
    "\n",
    "melt_denat_synthetic_dict = {}\n",
    "for melt in melts:\n",
    "    melt_denat_synthetic_dict[melt] = np.linspace(melt_lower_denat_dict[melt],\n",
    "                             melt_upper_denat_dict[melt], 300)\n",
    "\n",
    "construct1_denat_synthetic_dict = {}\n",
    "for construct in constructs:\n",
    "    construct1_denat_synthetic_dict[construct] = np.linspace(construct1_lower_denat_dict[construct],\n",
    "                                                             construct1_upper_denat_dict[construct], 300)\n",
    "\n",
    "''' Global Plot Aesthetics'''\n",
    "# Defining how the plots are colored\n",
    "num_melt_colors = num_melts\n",
    "num_construct_colors = num_constructs\n",
    "coloration = plt.get_cmap('hsv')\n",
    "\n",
    "\n",
    "# Dictonary defining title font\n",
    "title_font = {\n",
    "    'family': 'arial',\n",
    "    'color': 'black',\n",
    "    'weight': 'normal',\n",
    "    'size': 16\n",
    "}\n",
    "\n",
    "# Dictionary defining label font\n",
    "label_font = {\n",
    "    'family': 'arial',\n",
    "    'color': 'black',\n",
    "    'weight': 'normal',\n",
    "    'size': 14\n",
    "}\n",
    "\n",
    "'''First Plot: Fraction Folded by Melt'''\n",
    "#extracting the melt data and creating plot lines for each melt\n",
    "colorset = 0 # counter to control color of curves and points\n",
    "for melt in melts:   \n",
    "    colorset = colorset + 1\n",
    "    denat = melt_data_dict[melt][:,0]     # A numpy array of type str\n",
    "    norm_sig = melt_data_dict[melt][:,1]  # A numpy array of type str\n",
    "    denat = denat.astype(float) # A numpy array of type float\n",
    "    norm_sig = norm_sig.astype(float) # A numpy array of type float\n",
    "    y_adj = baseline_adj(norm_sig, denat, result.params, melt)\n",
    "    y_fit = fit_model(result.params, denat_fit, melt)\n",
    "    y_fit_adj = baseline_adj(y_fit, denat_fit, result.params, melt)\n",
    "    plt.plot(denat, y_adj, 'o', color = coloration(colorset/num_melt_colors),\n",
    "            label = melt[:-2] + ' melt ' + melt[-1])       \n",
    "    plt.plot(denat_fit, y_fit_adj, '-', color = coloration(colorset/num_melt_colors))\n",
    "\n",
    "#set axis limits\n",
    "axes=plt.gca()\n",
    "axes.set_xlim([-0.1, denat_bound])\n",
    "axes.set_ylim([-0.1,1.1])\n",
    "axes.set_aspect(5.5)\n",
    "\n",
    "#lot aesthetics and labels\n",
    "plt.legend(loc = 'center', bbox_to_anchor = (1.25, 0.5), fontsize=8)\n",
    "plt.title('Fraction Folded by Melt', fontdict = title_font)\n",
    "plt.xlabel('Denaturant (Molar)', fontdict = label_font)\n",
    "plt.ylabel('Fraction Folded', fontdict = label_font)\n",
    "\n",
    "#saving plot in individual doc\n",
    "plt.savefig(os.path.join(path, f'{proj_name}_plot_frac_folded_by_melt.png'),\\\n",
    "            dpi = 500, bbox_inches='tight')\n",
    "\n",
    "#show plot in iPython window and then close\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.clf\n",
    "\n",
    "'''Second Plot: Normalized Signal by Melt'''\n",
    "colorset = 0\n",
    "for melt in melts:   \n",
    "    colorset = colorset + 1\n",
    "    denat = melt_data_dict[melt][:,0]     # A numpy array of type str\n",
    "    norm_sig = melt_data_dict[melt][:,1]  # A numpy array of type str\n",
    "    denat = denat.astype(float) # A numpy array of type float\n",
    "    norm_sig = norm_sig.astype(float) # A numpy array of type float\n",
    "    y_fit = fit_model(result.params, melt_denat_synthetic_dict[melt], melt)\n",
    "    plt.plot(denat, norm_sig, 'o', color=coloration(colorset/num_melt_colors),\n",
    "             label = melt[:-2] + ' melt ' + melt[-1]) \n",
    "    plt.plot(melt_denat_synthetic_dict[melt], y_fit, '-', \\\n",
    "             color=coloration(colorset/num_melt_colors))\n",
    "\n",
    "#set axis limits\n",
    "axes=plt.gca()\n",
    "axes.set_xlim([-0.1, denat_bound])\n",
    "axes.set_ylim([-0.1,1.1])\n",
    "axes.set_aspect(5.5)\n",
    "\n",
    "#plot aesthetics and labels\n",
    "plt.legend(loc = 'center', bbox_to_anchor = (1.25, 0.5), fontsize=8)\n",
    "plt.title('Normalized Signal by Melt', fontdict = title_font)\n",
    "plt.xlabel('Denaturant (Molar)', fontdict = label_font)\n",
    "plt.ylabel('Normalized Signal', fontdict = label_font)\n",
    "\n",
    "#saving plot in individual doc\n",
    "plt.savefig(os.path.join(path, f'{proj_name}_plot_normalized_by_melt.png'),\\\n",
    "            dpi=500, bbox_inches='tight')\n",
    "\n",
    "#show plot in iPython window and then close\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.clf\n",
    "\n",
    "'''Third Plot: Fraction Folded by Construct'''\n",
    "colorset = 0\n",
    "for construct in constructs:   \n",
    "    colorset = colorset + 1\n",
    "    denat = construct1_data_dict[construct][:,0]  # A numpy array of type str\n",
    "    denat_line = construct1_data_dict[construct][:, 0]   # A numpy array of type str\n",
    "    norm_sig = construct1_data_dict[construct][:, 1]  # A numpy array of type str\n",
    "    denat = denat.astype(float) # A numpy array of type float\n",
    "    denat_line = denat_line.astype(float) # A numpy array of type float\n",
    "    norm_sig = norm_sig.astype(float) # A numpy array of type float\n",
    "    y_adj = baseline_adj(norm_sig, denat_line, result.params, construct + '_1')\n",
    "    y_fit = fit_model(result.params, denat_fit, construct + '_1')\n",
    "    y_fit_adj = baseline_adj(y_fit, denat_fit, result.params, construct + '_1')\n",
    "    plt.plot(denat, y_adj, 'o', \\\n",
    "             color=coloration(colorset/num_construct_colors), label = construct)       \n",
    "    plt.plot(denat_fit, y_fit_adj, '-', \\\n",
    "             color=coloration(colorset/num_construct_colors))\n",
    "\n",
    "#set axis limits\n",
    "axes=plt.gca()\n",
    "axes.set_xlim([-0.1, denat_bound])\n",
    "axes.set_ylim([-0.1,1.1])\n",
    "axes.set_aspect(5.5)\n",
    "\n",
    "#plot aesthetics and labels\n",
    "plt.legend(loc = 'center', bbox_to_anchor = (1.15, 0.5), fontsize=8)\n",
    "plt.title('Fraction Folded by Construct', fontdict = title_font)\n",
    "plt.xlabel('Denaturant (Molar)', fontdict = label_font)\n",
    "plt.ylabel('Fraction Folded', fontdict = label_font)\n",
    "\n",
    "#saving plot in individual doc\n",
    "plt.savefig(os.path.join(path, f'{proj_name}_plot_frac_folded_by_construct.png'),\\\n",
    "            dpi=500, bbox_inches='tight')\n",
    "\n",
    "#show plot in iPython window and then close\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.clf\n",
    "\n",
    "'''Fourth Plot: Normalized Signal by Construct'''\n",
    "colorset = 0\n",
    "for construct in constructs:   \n",
    "    colorset = colorset + 1\n",
    "    denat = construct1_data_dict[construct][:,0]     # A numpy array of type str\n",
    "    norm_sig = construct1_data_dict[construct][:,1]  # A numpy array of type str\n",
    "    denat = denat.astype(float) # A numpy array of type float\n",
    "    norm_sig = norm_sig.astype(float) # A numpy array of type float\n",
    "    y_fit = fit_model(result.params, construct1_denat_synthetic_dict[construct], \\\n",
    "                      construct + '_1')\n",
    "    plt.plot(denat, norm_sig, 'o', color = coloration(colorset/num_construct_colors),\n",
    "             label = construct) \n",
    "    plt.plot(construct1_denat_synthetic_dict[construct], y_fit, '-', \\\n",
    "             color = coloration(colorset/num_construct_colors))\n",
    "\n",
    "#set axis limits\n",
    "axes=plt.gca()\n",
    "axes.set_xlim([-0.1, denat_bound])\n",
    "axes.set_ylim([-0.1,1.1])\n",
    "axes.set_aspect(5.5)\n",
    "\n",
    "#plot aesthetics and labels\n",
    "plt.legend(loc = 'center', bbox_to_anchor = (1.15, 0.5), fontsize=8)\n",
    "plt.title('Normalized Signal by Construct', fontdict = title_font)\n",
    "plt.xlabel('Denaturant (Molar)', fontdict = label_font)\n",
    "plt.ylabel('Normalized Signal', fontdict = label_font)\n",
    "\n",
    "#saving plot in individual doc\n",
    "plt.savefig(os.path.join(path, f'{proj_name}_plot_normalized_by_construct.png'),\\\n",
    "            dpi=500, bbox_inches='tight')\n",
    "\n",
    "#show plot in iPython window and then close\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap analysis\n",
    "\n",
    "Asks the user to input the number of bootstrap iterations.  Bootstrap parameters are stored in a list of lists (**bs_param_values**). After performing the specified number of iterations, bootstrapped thermodynamic parameters are written to a csv file.\n",
    "\n",
    "Again, bootstrapping is meant to be performed after fitting above.  Otherwise, the data and the fit model will have to be re-imported, and the params list and objective function will need to be generated.  Just run the fit again if needed.\n",
    "\n",
    "In this version, a two minute sleep command is built in every 50 bootstrap iterations to let things cool down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''BootStrap analysis'''\n",
    "# Create list to store bootstrap iterations of values and define column titles\n",
    "bs_param_values = []  \n",
    "bs_param_values.append(['Bootstrap Iter', 'dGN', 'dGR', 'dGC', 'dGinter', 'mi', \n",
    "                        'redchi**2','bestchi**2'])   \n",
    "\n",
    "#total number of bootstrap iterations \n",
    "bs_iter_tot = input(\"How many bootstrap iterations? \") \n",
    "\n",
    "# bs_iter_tot = 10  # You would use this if you did not want user input from screen\n",
    "bs_iter_count = 0   # Iteration counter\n",
    "fit_resid_index= len(fit_resid) - 1\n",
    "\n",
    "y_fitted_dict = {}\n",
    "# Dictionary of 'true' normalized y values from fit at each denaturant value. \n",
    "for melt in melts:\n",
    "    denat = melt_data_dict[melt][:,0] # A numpy array of type str\n",
    "    denat = denat.astype(float)       # A numpy array of type float\n",
    "    y_fitted_dict[melt] = np.array(fit_model(result.params, denat, melt))\n",
    "\n",
    "# Arrays to store bs fitted param values\n",
    "dGN_vals = []\n",
    "dGR_vals = []\n",
    "dGC_vals = []\n",
    "dGinter_vals = []\n",
    "mi_vals = []\n",
    "\n",
    "# Add residuals chosen at random (with replacement) to expected\n",
    "# y values. Note-residuals are combined ACROSS melts.\n",
    "for j in range(int(bs_iter_tot)):   \n",
    "    rand_resid_dict={}  # Clears the random data for each bootsterap iteration\n",
    "    bs_iter_count = bs_iter_count + 1\n",
    "    print(\"Bootstrap iteration {0} out of {1}\".format(bs_iter_count, \n",
    "                               bs_iter_tot))\n",
    "    \n",
    "    for melt in melts:\n",
    "        rand_resid =[]\n",
    "        denat = melt_data_dict[melt][:,0] # A numpy array of type str\n",
    "        denat = denat.astype(float)       # A numpy array of type float\n",
    "        \n",
    "        for x in range(0,len(denat)):  # Creastes a list of random residuals\n",
    "            rand_int = np.random.randint(0, fit_resid_index)\n",
    "            rand_resid.append(fit_resid[rand_int])  \n",
    " \n",
    "        rand_resid_dict[melt] = np.array(rand_resid)\n",
    "        y_bootstrap = y_fitted_dict[melt] + rand_resid_dict[melt]\n",
    "        z_max,z_min = y_bootstrap.max(), y_bootstrap.min()\n",
    "        melt_data_dict[melt][:, 1] = (y_bootstrap - z_min)/(z_max - z_min)\n",
    "    \n",
    "    bs_result = lmfit.minimize(objective, init_guesses)\n",
    "    bs_chisqr = bs_result.chisqr\n",
    "    bs_red_chisqr= bs_result.redchi\n",
    "    \n",
    "    dGN = bs_result.params['dGN'].value\n",
    "    dGR = bs_result.params['dGR'].value\n",
    "    dGC = bs_result.params['dGC'].value\n",
    "    dGinter = bs_result.params['dGinter'].value\n",
    "    mi = bs_result.params['mi'].value\n",
    "    \n",
    "    # Store each value in a list for plotting and for downstream statistical analysis\n",
    "    dGN_vals.append(dGN)\n",
    "    dGR_vals.append(dGR)\n",
    "    dGC_vals.append(dGC)\n",
    "    dGinter_vals.append(dGinter)\n",
    "    mi_vals.append(mi)\n",
    "    \n",
    "    # Append bootstrapped global parameter values for ouput to a file\n",
    "    bs_param_values.append([bs_iter_count, dGN, dGR, dGC, dGinter, mi, \n",
    "                            bs_red_chisqr,bs_chisqr])\n",
    "        \n",
    "    \n",
    "with open(os.path.join(path, f'{proj_name}_bootstrap_params.csv'), \"w\") as n:\n",
    "    writer = csv.writer(n, delimiter = ',')\n",
    "    writer.writerows(bs_param_values)\n",
    "n.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The next cell calculates statistical properties of bootstrap parameters and outputs a file\n",
    "\n",
    "I plan to merge this with the bootstrap cell, but it is much more convenient to code it separately.  \n",
    "\n",
    "The structure that currently holds the bootstrap parameter values (*bs_param_values*) is a list of lists.  So it needs to be converted to a numpy array, and it needs to have only values, not column heads, in order to do numerical calculations.  Pandas would clearly be the right way to go with this, but not today.\n",
    "\n",
    "*path* (for writing out the data frame) is taken from the fitting cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_param_values_fullarray = np.array(bs_param_values)\n",
    "bs_param_values_array = bs_param_values_fullarray[1:,1:-2].astype(np.float) # End at -2 since last two columns\n",
    "                                                                            # are chi square statistics\n",
    "\n",
    "bs_param_names = bs_param_values_fullarray[0][1:-2]\n",
    "\n",
    "statistics = ['mean','median','stdev','2.5% CI','16.6% CI','83.7% CI','97.5% CI']\n",
    "\n",
    "bs_statistics_df = pd.DataFrame(columns = statistics)\n",
    "\n",
    "i = 0\n",
    "for param in bs_param_names:\n",
    "    bs_statistics = []\n",
    "    bs_statistics.append(np.mean(bs_param_values_array[:,i]))\n",
    "    bs_statistics.append(np.median(bs_param_values_array[:,i]))\n",
    "    bs_statistics.append(np.std(bs_param_values_array[:,i]))\n",
    "    bs_statistics.append(np.percentile(bs_param_values_array[:,i],2.5))\n",
    "    bs_statistics.append(np.percentile(bs_param_values_array[:,i],16.7))\n",
    "    bs_statistics.append(np.percentile(bs_param_values_array[:,i],83.3))\n",
    "    bs_statistics.append(np.percentile(bs_param_values_array[:,i],97.5))\n",
    "    bs_statistics_df.loc[param] = bs_statistics\n",
    "    i = i + 1\n",
    "\n",
    "bs_statistics_df.to_csv(os.path.join(path, f'{proj_name}_bootstrap_stats.csv'))\n",
    "\n",
    "corr_coef_matrix = np.corrcoef(bs_param_values_array, rowvar = False)\n",
    "corr_coef_df = pd.DataFrame(corr_coef_matrix, columns = bs_param_names, index = bs_param_names)\n",
    "corr_coef_df.to_csv(os.path.join(path, f'{proj_name}_bootstrap_corr_coefs.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_statistics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_coef_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_coef_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap histograms and correlation plots\n",
    "\n",
    "Plots are generated for the thermodynamic parameters of interest (currently, baseline parameters are not included, thought this would not be hard to generate).  Histograms are generated for each parameter.  Scatter plots are generated for each pair of parameters (not including self-correlation) and arrayed in a grid along with a linear fit.  Shared axes are used in the grid to minimize white-space resulting from labelling each axis.  Thinking about the output as a matrix, the histograms are on the main diagonal, and the correllation plots are off-diagonal elements populating the upper triangle of the matrix.\n",
    "\n",
    "The plot grid is dumped to the screen below, and is also written as a pdf file.\n",
    "\n",
    "As with the plotting and bootstrapping scripts above, this is meant to be run after the fitting script (and after the bootstrapping script immediately above).  If you have not done that, re-run fit and bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the names of parameters to be compared to see correlation.\n",
    "corr_params = ['dGN', 'dGR', 'dGC', 'dGinter', 'mi']\n",
    "\n",
    "# These are a second set of parameter names that follow in the same order\n",
    "# as in corr_params.  They are formatted using TeX-style names so that Deltas \n",
    "# and subscripts will be plotted.  The would not be good key names for dictionaries\n",
    "corr_param_labels = ['$\\Delta$G$_N$', '$\\Delta$G$_R$', '$\\Delta$G$_C$', \n",
    "               '$\\Delta$G$_{i, i-1}$', 'm$_i$']\n",
    "\n",
    "num_corr_params = len(corr_params)\n",
    "gridsize = num_corr_params  # Determines the size of the plot grid.\n",
    "\n",
    "# Dictionary of fitted parameter values.\n",
    "corr_params_dict = {'dGN': dGN_vals, 'dGR': dGR_vals, 'dGC': dGC_vals,\\\n",
    "                    'dGinter': dGinter_vals, 'mi': mi_vals}\n",
    "\n",
    "# PDF that stores a grid of the correlation plots\n",
    "with PdfPages(os.path.join(path, f'{proj_name}_Corr_Plots.pdf')) as pdf:\n",
    "    fig, axs = plt.subplots(ncols=gridsize, nrows=gridsize, figsize=(12, 12))\n",
    "    \n",
    "    # Turns off axes on lower triangle\n",
    "    axs[1, 0].axis('off')\n",
    "    axs[2, 0].axis('off')\n",
    "    axs[2, 1].axis('off')\n",
    "    axs[3, 0].axis('off')\n",
    "    axs[3, 1].axis('off')\n",
    "    axs[3, 2].axis('off')\n",
    "    axs[4, 0].axis('off')\n",
    "    axs[4, 1].axis('off')\n",
    "    axs[4, 2].axis('off')\n",
    "    axs[4, 3].axis('off')\n",
    "\n",
    "    # Defines the position of the y paramater from the array of params\n",
    "    hist_param_counter = 0\n",
    "    while hist_param_counter < num_corr_params:\n",
    "        hist_param_label = corr_param_labels[hist_param_counter]\n",
    "        hist_param = corr_params[hist_param_counter]\n",
    "        # Start fixing labels here\n",
    "        #plt.xticks(fontsize=8)\n",
    "        #axs[hist_param_counter, hist_param_counter].tick_params(fontsize=8)\n",
    "        #axs[hist_param_counter, hist_param_counter].yticks(fontsize=8)\n",
    "        axs[hist_param_counter, hist_param_counter].hist(corr_params_dict[hist_param])\n",
    "        axs[hist_param_counter, hist_param_counter].set_xlabel(hist_param_label,\n",
    "                   fontsize=14, labelpad = 5)\n",
    "        hist_param_counter = hist_param_counter + 1  \n",
    "    \n",
    "    # This part generates the correlation plots\n",
    "    y_param_counter = 0\n",
    "    while y_param_counter < num_corr_params - 1:\n",
    "        # Pulls the parameter name for the y-axis label (with TeX formatting)\n",
    "        yparam_label = corr_param_labels[y_param_counter]\n",
    "        # Pulls the parameter name to be plotted on the y-axis\n",
    "        yparam = corr_params[y_param_counter]\n",
    "        \n",
    "        # Defines the position of the x paramater from the array of params.\n",
    "        # The + 1 offest avoids correlating a parameter with itself.\n",
    "        x_param_counter = y_param_counter + 1\n",
    "        \n",
    "        while (x_param_counter < num_corr_params):\n",
    "            #pulls the parameter name for the x-axis label (with TeX formatting)\n",
    "            xparam_label = corr_param_labels[x_param_counter]\n",
    "            # Pulls the parameter name to be plotted on the x-axis\n",
    "            xparam = corr_params[x_param_counter]\n",
    "            \n",
    "            x_vals= corr_params_dict[xparam]\n",
    "            y_vals = corr_params_dict[yparam]\n",
    "            \n",
    "            #plt.xticks(fontsize=8)\n",
    "            #plt.yticks(fontsize=8)\n",
    "            #plotting scatters with axes.  +1 shifts a plot to the right from main diagonal\n",
    "            axs[y_param_counter, x_param_counter].plot(x_vals, y_vals, '.')\n",
    "            \n",
    "            # The if statement below turns off numbers on axes if not the right column and\n",
    "            # not the main diagonal.\n",
    "            if x_param_counter < num_corr_params - 1:\n",
    "                axs[y_param_counter, x_param_counter].set_xticklabels([])\n",
    "                axs[y_param_counter, x_param_counter].set_yticklabels([])\n",
    "                           \n",
    "            if y_param_counter == 0:  # Puts labels above axes on top row\n",
    "                axs[y_param_counter, x_param_counter].xaxis.set_label_position('top')\n",
    "                axs[y_param_counter, x_param_counter].set_xlabel(xparam_label,\n",
    "                   labelpad = 10, fontsize=14)\n",
    "                axs[y_param_counter, x_param_counter].xaxis.tick_top()\n",
    "                if x_param_counter < num_corr_params - 1:  # Avoids eliminating y-scale from upper right corner\n",
    "                    axs[y_param_counter, x_param_counter].set_yticklabels([])\n",
    "           \n",
    "            if x_param_counter == num_corr_params - 1:  #  Puts labels right of right column\n",
    "                axs[y_param_counter, x_param_counter].yaxis.set_label_position('right')\n",
    "                axs[y_param_counter, x_param_counter].set_ylabel(yparam_label, \n",
    "                   rotation = 0, labelpad = 30, fontsize=14)\n",
    "                axs[y_param_counter, x_param_counter].set_xticklabels([])\n",
    "                axs[y_param_counter, x_param_counter].yaxis.tick_right()\n",
    "               \n",
    "            # Determin correlation coefficient and display under subplot title\n",
    "            # Note, there is no code that displays this value at the moment.\n",
    "            #corr_coef = np.around(np.corrcoef(x_vals, y_vals), 3)\n",
    "            \n",
    "            #min and max values of the x param\n",
    "            x_min = min(x_vals)\n",
    "            x_max = max(x_vals)\n",
    "            \n",
    "            #fitting a straight line to the correlation scatterplot\n",
    "            fit_array = np.polyfit(x_vals, y_vals, 1)\n",
    "            fit_deg1_coef = fit_array[0]\n",
    "            fit_deg0_coef = fit_array[1]      \n",
    "            fit_x_vals = np.linspace(x_min, x_max, 10)\n",
    "            fit_y_vals = fit_deg1_coef*fit_x_vals + fit_deg0_coef\n",
    "            \n",
    "            #plotting correlation line fits\n",
    "            axs[y_param_counter, x_param_counter].plot(fit_x_vals, \n",
    "               fit_y_vals)\n",
    "            plt.subplots_adjust(wspace=0, hspace=0)\n",
    "            \n",
    "            x_param_counter = x_param_counter + 1            \n",
    "        y_param_counter = y_param_counter + 1\n",
    "    \n",
    "    pdf.savefig(bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
