{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data conversion from *two* csv files.\n",
    "\n",
    "In this script, data are read from two csv files using pandas dataframes.  There is a csv file for the T4V data, and a second for the NRC data.  Imported to dataframes and combined into a final dataframe.\n",
    "Outputs are\n",
    "\n",
    "1.  A numpy data file for each melt, contining [denaturant], normalized signal, construct ID, and melt ID.\n",
    "\n",
    "2.  A list of constructs.\n",
    "\n",
    "3.  A list of melts.\n",
    "\n",
    "4.  A combined csv file with all melts (T4V and NRC).\n",
    "\n",
    "For the lists of constructs and melts, there are loops that attempt to put the constructs and melts in order so that they appear in a logical progression from short to long and depending on repeat type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "path = '/Users/dougbarrick/OneDrive - Johns Hopkins/Manuscripts/Ising_program/\\\n",
    "Scripts/scripts_mutations/T4V_two_mi_values_2020_05_10/'\n",
    "\n",
    "proj_name = 'T4V_NRC_2mi'\n",
    "\n",
    "den_nsig_const_melt = []\n",
    "constructs = []         # List of constructs used to build partition functions in next script\n",
    "melts = []              # List of melts to be used in fitting script\n",
    "\n",
    "T4V_input_df = pd.read_csv('T4Vdata_not_normalized.csv',names=['denat','signal','construct_melt','dataset'])\n",
    "NRC_input_df = pd.read_csv('NRC_data_dnmn.csv',names=['denat','signal','construct_melt','dataset'])\n",
    "maxT4Vmelt = T4V_input_df['dataset'].max()  # Finds the maximum number of melts in the first df\n",
    "NRC_input_df['dataset'] = NRC_input_df['dataset'] + maxT4Vmelt # Adds the max number to the melt numbers in second df\n",
    "combined_input_df = pd.concat([T4V_input_df, NRC_input_df],names=['denat','signal','construct_melt','dataset'])\n",
    "combined_input_df.to_csv('{}T4V_NRC_dnmn.csv'.format(path), index=False, header=False)\n",
    "\n",
    "num_melts=combined_input_df['dataset'].max()\n",
    "for melt in np.arange(num_melts)+1:\n",
    "    temp_df = combined_input_df.loc[combined_input_df.dataset == melt] # Pulls out just one melt\n",
    "        \n",
    "    # Normalizing the signal\n",
    "    min = temp_df['signal'].min()\n",
    "    max = temp_df['signal'].max()\n",
    "    series=(temp_df['signal'] - min)/(max - min)\n",
    "    temp_df['signal'] = series  # Overwrites un-normalized signal\n",
    "    temp_df.rename(columns={'signal': 'nsig'}, inplace=True)\n",
    "    temp_list = temp_df.values.tolist()\n",
    "    temp_nparray = np.array(temp_list)\n",
    "    construct_melt = temp_df.iloc[0, 2]\n",
    "    np.save(path + construct_melt, temp_nparray) # Writes an npy file to disk for each melt.\n",
    "    melts.append(construct_melt)\n",
    "\n",
    "''' \n",
    "This loop puts melts in order of type (NRxC, NRx, RxC) and length.  This is useful for the\n",
    "plotting script below, putting the by_melt legends in a sensible order\n",
    "'''\n",
    "NRClist = []\n",
    "NRlist = []\n",
    "RClist = []\n",
    "melts.sort()\n",
    "i = 0\n",
    "for melt in melts:\n",
    "    if melt[0] == 'N':\n",
    "        if melt[-3] == 'C':\n",
    "            NRClist.append(melt)\n",
    "        else:\n",
    "            NRlist.append(melt)\n",
    "    else:\n",
    "        RClist.append(melt)\n",
    "\n",
    "NRClist.sort(key=len)\n",
    "NRlist.sort(key=len)\n",
    "RClist.sort(key=len)\n",
    "melts = NRClist + NRlist + RClist\n",
    "    \n",
    "# Generate a list of just the constructs.  The loop removes duplicates.\n",
    "for melt in melts: \n",
    "    if melt[:-2] not in constructs: \n",
    "        constructs.append(melt[:-2]) \n",
    "         \n",
    "with open(\"{0}{1}_constructs.txt\".format(path, proj_name), 'wb') as r:\n",
    "    json.dump(constructs, r)\n",
    "\n",
    "with open(\"{0}{1}_melts.txt\".format(path, proj_name), 'wb') as s:\n",
    "    json.dump(melts, s)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
